{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed8a9fa",
   "metadata": {},
   "source": [
    "# üè† Analyse Exploratoire et Pr√©diction des Prix Immobiliers\n",
    "\n",
    "## Projet d'Analyse de Donn√©es - Math IA\n",
    "\n",
    "**Auteur:** Projet Math IA  \n",
    "**Date:** Juin 2025  \n",
    "**Objectif:** D√©velopper un mod√®le de r√©gression multiple pour pr√©dire les prix des biens immobiliers\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Objectifs du Projet\n",
    "\n",
    "1. **Collecte des donn√©es** : Scraper les annonces immobili√®res\n",
    "2. **Nettoyage des donn√©es** : Construire une pipeline de traitement\n",
    "3. **Analyse exploratoire** : Explorer les relations entre variables\n",
    "4. **Mod√©lisation** : D√©velopper un mod√®le de r√©gression multiple\n",
    "5. **√âvaluation** : Analyser les performances et l'importance des variables\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Structure du Notebook\n",
    "\n",
    "1. Import des biblioth√®ques requises\n",
    "2. Chargement et inspection des donn√©es\n",
    "3. Pr√©traitement des donn√©es\n",
    "4. Ing√©nierie des features\n",
    "5. S√©lection et entra√Ænement des mod√®les\n",
    "6. √âvaluation des mod√®les\n",
    "7. Optimisation des hyperparam√®tres\n",
    "8. Sauvegarde et chargement du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f6a89",
   "metadata": {},
   "source": [
    "## 1. Import des Biblioth√®ques Requises\n",
    "\n",
    "Importation de toutes les biblioth√®ques n√©cessaires pour l'analyse de donn√©es, la visualisation et la mod√©lisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation de donn√©es\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Statistiques\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Utilitaires\n",
    "import joblib\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Ajout du r√©pertoire parent au path pour importer nos modules\n",
    "sys.path.append('..')\n",
    "\n",
    "print(\"‚úÖ Toutes les biblioth√®ques ont √©t√© import√©es avec succ√®s!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")\n",
    "print(f\"ü§ñ Scikit-learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd587fe1",
   "metadata": {},
   "source": [
    "## 2. Chargement et Inspection des Donn√©es\n",
    "\n",
    "Dans cette section, nous chargeons les donn√©es immobili√®res et effectuons une inspection initiale pour comprendre la structure et la qualit√© des donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es\n",
    "data_path = '../data/raw_properties.csv'\n",
    "\n",
    "# V√©rification de l'existence du fichier\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"‚ùå Fichier de donn√©es non trouv√©!\")\n",
    "    print(\"Ex√©cutez d'abord le script de collecte de donn√©es ou le script principal.\")\n",
    "    print(\"Alternative: g√©n√©ration de donn√©es d'exemple...\")\n",
    "    \n",
    "    # G√©n√©ration de donn√©es d'exemple si le fichier n'existe pas\n",
    "    from src.data_scraper import generate_sample_data\n",
    "    df_raw = generate_sample_data(200)\n",
    "    os.makedirs('../data', exist_ok=True)\n",
    "    df_raw.to_csv(data_path, index=False)\n",
    "    print(\"‚úÖ Donn√©es d'exemple g√©n√©r√©es et sauvegard√©es!\")\n",
    "else:\n",
    "    # Chargement des donn√©es existantes\n",
    "    df_raw = pd.read_csv(data_path)\n",
    "    print(\"‚úÖ Donn√©es charg√©es avec succ√®s!\")\n",
    "\n",
    "print(f\"üìä Nombre de propri√©t√©s: {len(df_raw)}\")\n",
    "print(f\"üìà Nombre de variables: {len(df_raw.columns)}\")\n",
    "print(f\"üìÖ P√©riode de donn√©es: {pd.Timestamp.now().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Affichage des premi√®res lignes\n",
    "print(\"\\nüîç Aper√ßu des donn√©es:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c6b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspection d√©taill√©e des donn√©es\n",
    "print(\"üìã INFORMATIONS SUR LE DATASET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Informations g√©n√©rales\n",
    "print(f\"Forme du dataset: {df_raw.shape}\")\n",
    "print(f\"Taille m√©moire: {df_raw.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\nüìä TYPES DE DONN√âES:\")\n",
    "print(df_raw.dtypes)\n",
    "\n",
    "print(\"\\nüîç INFORMATIONS D√âTAILL√âES:\")\n",
    "df_raw.info()\n",
    "\n",
    "print(\"\\nüìà STATISTIQUES DESCRIPTIVES:\")\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dac5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des valeurs manquantes\n",
    "print(\"üö® ANALYSE DES VALEURS MANQUANTES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "missing_values = df_raw.isnull().sum()\n",
    "missing_percent = (missing_values / len(df_raw)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Colonnes': missing_values.index,\n",
    "    'Valeurs_manquantes': missing_values.values,\n",
    "    'Pourcentage': missing_percent.values\n",
    "}).sort_values('Pourcentage', ascending=False)\n",
    "\n",
    "print(missing_df)\n",
    "\n",
    "# Visualisation des valeurs manquantes\n",
    "if missing_values.sum() > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Graphique en barres des valeurs manquantes\n",
    "    plt.subplot(1, 2, 1)\n",
    "    missing_cols = missing_df[missing_df['Valeurs_manquantes'] > 0]\n",
    "    plt.bar(missing_cols['Colonnes'], missing_cols['Pourcentage'], color='red', alpha=0.7)\n",
    "    plt.title('Pourcentage de Valeurs Manquantes par Colonne')\n",
    "    plt.ylabel('Pourcentage (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Heatmap des valeurs manquantes\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(df_raw.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "    plt.title('Heatmap des Valeurs Manquantes')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚úÖ Aucune valeur manquante d√©tect√©e!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc1f034",
   "metadata": {},
   "source": [
    "## 3. Pr√©traitement des Donn√©es\n",
    "\n",
    "Le pr√©traitement est une √©tape cruciale qui inclut:\n",
    "- Nettoyage des donn√©es (suppression des doublons, gestion des outliers)\n",
    "- Gestion des valeurs manquantes\n",
    "- Validation des donn√©es selon des r√®gles m√©tier\n",
    "- Normalisation et standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de notre pipeline de nettoyage personnalis√©\n",
    "from src.data_pipeline import DataCleaner\n",
    "\n",
    "print(\"üßπ NETTOYAGE DES DONN√âES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialisation du nettoyeur\n",
    "cleaner = DataCleaner()\n",
    "\n",
    "# Nettoyage des donn√©es\n",
    "df_cleaned = cleaner.clean_data(df_raw)\n",
    "\n",
    "# Rapport de nettoyage\n",
    "cleaning_report = cleaner.generate_cleaning_report(df_raw, df_cleaned)\n",
    "\n",
    "print(\"üìä RAPPORT DE NETTOYAGE:\")\n",
    "print(f\"‚Ä¢ Lignes originales: {cleaning_report['original_rows']}\")\n",
    "print(f\"‚Ä¢ Lignes nettoy√©es: {cleaning_report['cleaned_rows']}\")\n",
    "print(f\"‚Ä¢ Lignes supprim√©es: {cleaning_report['rows_removed']} ({cleaning_report['removal_percentage']:.1f}%)\")\n",
    "print(f\"‚Ä¢ Nouvelles features cr√©√©es: {len(cleaning_report['new_features'])}\")\n",
    "\n",
    "if cleaning_report['new_features']:\n",
    "    print(\"‚Ä¢ Features ajout√©es:\")\n",
    "    for feature in cleaning_report['new_features']:\n",
    "        print(f\"  - {feature}\")\n",
    "\n",
    "print(\"\\n‚úÖ Donn√©es nettoy√©es avec succ√®s!\")\n",
    "print(f\"üìä Nouvelles dimensions: {df_cleaned.shape}\")\n",
    "\n",
    "# Aper√ßu des donn√©es nettoy√©es\n",
    "print(\"\\nüîç Aper√ßu des donn√©es nettoy√©es:\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212bac3",
   "metadata": {},
   "source": [
    "## 4. Analyse Exploratoire des Donn√©es (EDA)\n",
    "\n",
    "L'analyse exploratoire nous permet de:\n",
    "- Comprendre la distribution des variables\n",
    "- Identifier les corr√©lations entre variables\n",
    "- D√©tecter les patterns et tendances du march√© immobilier\n",
    "- Pr√©parer les insights pour la mod√©lisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Distribution des prix\n",
    "print(\"üí∞ ANALYSE DE LA DISTRIBUTION DES PRIX\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Distribution des Prix Immobiliers', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Histogramme des prix\n",
    "axes[0, 0].hist(df_cleaned['prix_dh'], bins=50, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Histogramme des Prix')\n",
    "axes[0, 0].set_xlabel('Prix (DH)')\n",
    "axes[0, 0].set_ylabel('Fr√©quence')\n",
    "axes[0, 0].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
    "\n",
    "# Box plot des prix\n",
    "bp = axes[0, 1].boxplot(df_cleaned['prix_dh'], patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('lightcoral')\n",
    "axes[0, 1].set_title('Box Plot des Prix')\n",
    "axes[0, 1].set_ylabel('Prix (DH)')\n",
    "axes[0, 1].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "\n",
    "# Distribution log des prix\n",
    "prix_log = np.log10(df_cleaned['prix_dh'])\n",
    "axes[1, 0].hist(prix_log, bins=50, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Distribution des Prix (√©chelle log)')\n",
    "axes[1, 0].set_xlabel('Log10(Prix)')\n",
    "axes[1, 0].set_ylabel('Fr√©quence')\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(df_cleaned['prix_dh'], dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('Q-Q Plot (Distribution normale)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques de prix\n",
    "print(f\"üìä Statistiques des prix:\")\n",
    "print(f\"‚Ä¢ Prix moyen: {df_cleaned['prix_dh'].mean():,.0f} DH\")\n",
    "print(f\"‚Ä¢ Prix m√©dian: {df_cleaned['prix_dh'].median():,.0f} DH\")\n",
    "print(f\"‚Ä¢ Prix minimum: {df_cleaned['prix_dh'].min():,.0f} DH\")\n",
    "print(f\"‚Ä¢ Prix maximum: {df_cleaned['prix_dh'].max():,.0f} DH\")\n",
    "print(f\"‚Ä¢ √âcart-type: {df_cleaned['prix_dh'].std():,.0f} DH\")\n",
    "print(f\"‚Ä¢ Coefficient de variation: {(df_cleaned['prix_dh'].std() / df_cleaned['prix_dh'].mean()):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f71652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Analyse des corr√©lations\n",
    "print(\"\\nüîó ANALYSE DES CORR√âLATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# S√©lection des variables num√©riques\n",
    "numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df_cleaned[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Cr√©ation de la heatmap\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, \n",
    "           mask=mask,\n",
    "           annot=True, \n",
    "           cmap='RdBu_r', \n",
    "           center=0,\n",
    "           square=True,\n",
    "           fmt='.2f',\n",
    "           cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.title('Matrice de Corr√©lation des Variables Num√©riques', \n",
    "         fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Corr√©lations avec le prix\n",
    "price_correlations = correlation_matrix['prix_dh'].abs().sort_values(ascending=False)\n",
    "print(\"üìä Corr√©lations avec le prix (valeurs absolues):\")\n",
    "for var, corr in price_correlations.items():\n",
    "    if var != 'prix_dh':\n",
    "        print(f\"‚Ä¢ {var}: {corr:.3f}\")\n",
    "\n",
    "# Variables les plus corr√©l√©es avec le prix\n",
    "top_correlations = price_correlations.drop('prix_dh').head(5)\n",
    "print(f\"\\nüèÜ Top 5 des variables les plus corr√©l√©es avec le prix:\")\n",
    "for i, (var, corr) in enumerate(top_correlations.items(), 1):\n",
    "    print(f\"{i}. {var}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a594f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Analyse par localisation et type de bien\n",
    "print(\"\\nüó∫Ô∏è ANALYSE PAR LOCALISATION ET TYPE DE BIEN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Analyse par Localisation et Type de Bien', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Prix moyen par ville\n",
    "prix_par_ville = df_cleaned.groupby('localisation')['prix_dh'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "\n",
    "bars1 = axes[0, 0].bar(range(len(prix_par_ville)), prix_par_ville['mean'], \n",
    "                      color='steelblue', alpha=0.7)\n",
    "axes[0, 0].set_title('Prix Moyen par Ville')\n",
    "axes[0, 0].set_xlabel('Ville')\n",
    "axes[0, 0].set_ylabel('Prix Moyen (DH)')\n",
    "axes[0, 0].set_xticks(range(len(prix_par_ville)))\n",
    "axes[0, 0].set_xticklabels(prix_par_ville.index, rotation=45)\n",
    "axes[0, 0].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "\n",
    "# Nombre de propri√©t√©s par ville\n",
    "bars2 = axes[0, 1].bar(range(len(prix_par_ville)), prix_par_ville['count'], \n",
    "                      color='orange', alpha=0.7)\n",
    "axes[0, 1].set_title('Nombre de Propri√©t√©s par Ville')\n",
    "axes[0, 1].set_xlabel('Ville')\n",
    "axes[0, 1].set_ylabel('Nombre de Propri√©t√©s')\n",
    "axes[0, 1].set_xticks(range(len(prix_par_ville)))\n",
    "axes[0, 1].set_xticklabels(prix_par_ville.index, rotation=45)\n",
    "\n",
    "# Distribution par type de bien\n",
    "if 'type_bien' in df_cleaned.columns:\n",
    "    type_counts = df_cleaned['type_bien'].value_counts()\n",
    "    wedges, texts, autotexts = axes[1, 0].pie(type_counts.values, labels=type_counts.index, \n",
    "                                             autopct='%1.1f%%', startangle=90)\n",
    "    axes[1, 0].set_title('R√©partition par Type de Bien')\n",
    "    \n",
    "    # Prix moyen par type de bien\n",
    "    prix_par_type = df_cleaned.groupby('type_bien')['prix_dh'].mean().sort_values(ascending=True)\n",
    "    bars3 = axes[1, 1].barh(range(len(prix_par_type)), prix_par_type.values,\n",
    "                           color='lightcoral', alpha=0.7)\n",
    "    axes[1, 1].set_title('Prix Moyen par Type de Bien')\n",
    "    axes[1, 1].set_xlabel('Prix Moyen (DH)')\n",
    "    axes[1, 1].set_yticks(range(len(prix_par_type)))\n",
    "    axes[1, 1].set_yticklabels(prix_par_type.index)\n",
    "    axes[1, 1].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Insights par localisation\n",
    "print(\"üèôÔ∏è Insights par localisation:\")\n",
    "ville_plus_chere = prix_par_ville.index[0]\n",
    "prix_plus_cher = prix_par_ville['mean'].iloc[0]\n",
    "ville_moins_chere = prix_par_ville.index[-1]\n",
    "prix_moins_cher = prix_par_ville['mean'].iloc[-1]\n",
    "\n",
    "print(f\"‚Ä¢ Ville la plus ch√®re: {ville_plus_chere} ({prix_plus_cher:,.0f} DH)\")\n",
    "print(f\"‚Ä¢ Ville la moins ch√®re: {ville_moins_chere} ({prix_moins_cher:,.0f} DH)\")\n",
    "print(f\"‚Ä¢ √âcart de prix: {((prix_plus_cher - prix_moins_cher) / prix_moins_cher * 100):.1f}%\")\n",
    "\n",
    "if 'type_bien' in df_cleaned.columns:\n",
    "    print(f\"\\nüè† Insights par type de bien:\")\n",
    "    type_plus_cher = prix_par_type.index[-1]\n",
    "    type_moins_cher = prix_par_type.index[0]\n",
    "    print(f\"‚Ä¢ Type le plus cher: {type_plus_cher} ({prix_par_type.iloc[-1]:,.0f} DH)\")\n",
    "    print(f\"‚Ä¢ Type le moins cher: {type_moins_cher} ({prix_par_type.iloc[0]:,.0f} DH)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486ac5f",
   "metadata": {},
   "source": [
    "## 5. S√©lection et Entra√Ænement des Mod√®les\n",
    "\n",
    "Dans cette section, nous:\n",
    "- Pr√©parons les donn√©es pour la mod√©lisation\n",
    "- Testons plusieurs algorithmes de r√©gression\n",
    "- Comparons leurs performances\n",
    "- S√©lectionnons le meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Pr√©paration des donn√©es pour la mod√©lisation\n",
    "print(\"ü§ñ PR√âPARATION DES DONN√âES POUR LA MOD√âLISATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Utilisation de notre pr√©dicteur personnalis√©\n",
    "from src.modeling import RealEstatePricePredictor\n",
    "\n",
    "# Initialisation du pr√©dicteur\n",
    "predictor = RealEstatePricePredictor()\n",
    "\n",
    "# Pr√©paration des donn√©es\n",
    "X_train, X_test, y_train, y_test = predictor.prepare_data(df_cleaned)\n",
    "\n",
    "print(f\"‚úÖ Donn√©es pr√©par√©es pour {len(predictor.feature_names)} features\")\n",
    "print(f\"üìä Taille d'entra√Ænement: {X_train.shape}\")\n",
    "print(f\"üìä Taille de test: {X_test.shape}\")\n",
    "\n",
    "# 5.2 Entra√Ænement des mod√®les\n",
    "print(\"\\nüöÄ ENTRA√éNEMENT DES MOD√àLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Entra√Ænement de tous les mod√®les\n",
    "results = predictor.train_models(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# S√©lection du meilleur mod√®le\n",
    "best_model_name = predictor.select_best_model()\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le s√©lectionn√©: {best_model_name}\")\n",
    "\n",
    "# R√©capitulatif des performances\n",
    "print(\"\\nüìä R√âCAPITULATIF DES PERFORMANCES:\")\n",
    "print(\"-\" * 40)\n",
    "performance_df = pd.DataFrame()\n",
    "\n",
    "for name, result in results.items():\n",
    "    performance_df = pd.concat([performance_df, pd.DataFrame({\n",
    "        'Mod√®le': [name],\n",
    "        'R¬≤': [result['test_metrics']['r2']],\n",
    "        'RMSE': [result['test_metrics']['rmse']],\n",
    "        'MAE': [result['test_metrics']['mae']],\n",
    "        'MAPE (%)': [result['test_metrics']['mape']]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "# Tri par R¬≤ d√©croissant\n",
    "performance_df = performance_df.sort_values('R¬≤', ascending=False)\n",
    "print(performance_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492709ee",
   "metadata": {},
   "source": [
    "## 6. √âvaluation des Mod√®les\n",
    "\n",
    "Nous √©valuons les mod√®les selon plusieurs crit√®res:\n",
    "- **R¬≤** : Coefficient de d√©termination (plus proche de 1 = meilleur)\n",
    "- **RMSE** : Root Mean Square Error (plus bas = meilleur)\n",
    "- **MAE** : Mean Absolute Error (plus bas = meilleur)\n",
    "- **MAPE** : Mean Absolute Percentage Error (plus bas = meilleur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a32b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Visualisation des performances des mod√®les\n",
    "print(\"üìä VISUALISATION DES PERFORMANCES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Graphique de comparaison des mod√®les\n",
    "predictor.plot_model_comparison(save=False)\n",
    "\n",
    "# 6.2 Analyse d√©taill√©e du meilleur mod√®le\n",
    "print(f\"\\nüîç ANALYSE D√âTAILL√âE - {best_model_name}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Graphique pr√©dictions vs r√©elles\n",
    "predictor.plot_predictions_vs_actual(X_test, y_test, save=False)\n",
    "\n",
    "# Analyse de l'importance des features\n",
    "print(\"\\nüìà IMPORTANCE DES FEATURES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "importance_df = predictor.analyze_feature_importance()\n",
    "if not importance_df.empty:\n",
    "    print(\"Top 10 des features les plus importantes:\")\n",
    "    top_features = importance_df.head(10)\n",
    "    for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:<25} : {row['importance']:.4f}\")\n",
    "    \n",
    "    # Graphique d'importance\n",
    "    predictor.plot_feature_importance(save=False)\n",
    "else:\n",
    "    print(\"‚ùå Importance des features non disponible pour ce mod√®le\")\n",
    "\n",
    "# 6.3 M√©triques d√©taill√©es du meilleur mod√®le\n",
    "best_metrics = results[best_model_name]['test_metrics']\n",
    "train_metrics = results[best_model_name]['train_metrics']\n",
    "\n",
    "print(f\"\\nüìä M√âTRIQUES D√âTAILL√âES - {best_model_name}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Performances sur les donn√©es de TEST:\")\n",
    "print(f\"‚Ä¢ R¬≤ Score        : {best_metrics['r2']:.4f}\")\n",
    "print(f\"‚Ä¢ RMSE           : {best_metrics['rmse']:,.0f} DH\")\n",
    "print(f\"‚Ä¢ MAE            : {best_metrics['mae']:,.0f} DH\")\n",
    "print(f\"‚Ä¢ MAPE           : {best_metrics['mape']:.2f}%\")\n",
    "\n",
    "print(\"\\nPerformances sur les donn√©es d'ENTRA√éNEMENT:\")\n",
    "print(f\"‚Ä¢ R¬≤ Score        : {train_metrics['r2']:.4f}\")\n",
    "print(f\"‚Ä¢ RMSE           : {train_metrics['rmse']:,.0f} DH\")\n",
    "print(f\"‚Ä¢ MAE            : {train_metrics['mae']:,.0f} DH\")\n",
    "print(f\"‚Ä¢ MAPE           : {train_metrics['mape']:.2f}%\")\n",
    "\n",
    "# D√©tection d'overfitting\n",
    "r2_diff = train_metrics['r2'] - best_metrics['r2']\n",
    "if r2_diff > 0.1:\n",
    "    print(f\"\\n‚ö†Ô∏è  ATTENTION: Possible overfitting d√©tect√©!\")\n",
    "    print(f\"   Diff√©rence R¬≤ (train - test): {r2_diff:.3f}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Pas d'overfitting d√©tect√© (diff√©rence R¬≤: {r2_diff:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c392fa",
   "metadata": {},
   "source": [
    "## 7. Optimisation des Hyperparam√®tres\n",
    "\n",
    "L'optimisation des hyperparam√®tres permet d'am√©liorer les performances du mod√®le en trouvant les meilleurs param√®tres pour chaque algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b533a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Optimisation des hyperparam√®tres\n",
    "print(\"‚öôÔ∏è  OPTIMISATION DES HYPERPARAM√àTRES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Optimisation pour les mod√®les s√©lectionn√©s\n",
    "optimized_models = predictor.hyperparameter_tuning(X_train, y_train)\n",
    "\n",
    "if optimized_models:\n",
    "    print(\"\\nüìä R√âSULTATS DE L'OPTIMISATION:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for name, result in optimized_models.items():\n",
    "        print(f\"\\nüîß {name}:\")\n",
    "        print(f\"   Meilleurs param√®tres: {result['best_params']}\")\n",
    "        print(f\"   Score CV RMSE: {np.sqrt(result['best_score']):,.0f} DH\")\n",
    "        \n",
    "        # Comparaison avec le mod√®le de base\n",
    "        base_rmse = results[name]['test_metrics']['rmse']\n",
    "        optimized_rmse = np.sqrt(result['best_score'])\n",
    "        improvement = ((base_rmse - optimized_rmse) / base_rmse) * 100\n",
    "        \n",
    "        if improvement > 0:\n",
    "            print(f\"   üìà Am√©lioration: {improvement:.1f}%\")\n",
    "        else:\n",
    "            print(f\"   üìâ D√©gradation: {abs(improvement):.1f}%\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Optimisation d√©sactiv√©e pour cette d√©mo (peut prendre du temps)\")\n",
    "\n",
    "# 7.2 Test du mod√®le optimis√© (simulation)\n",
    "print(f\"\\nüéØ PERFORMANCE DU MOD√àLE FINAL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Utilisation du meilleur mod√®le actuel\n",
    "final_model = predictor.best_model\n",
    "final_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Calcul des m√©triques finales\n",
    "final_r2 = r2_score(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "final_mae = mean_absolute_error(y_test, final_predictions)\n",
    "final_mape = np.mean(np.abs((y_test - final_predictions) / y_test)) * 100\n",
    "\n",
    "print(f\"Mod√®le final: {best_model_name}\")\n",
    "print(f\"‚Ä¢ R¬≤ Score : {final_r2:.4f}\")\n",
    "print(f\"‚Ä¢ RMSE     : {final_rmse:,.0f} DH\")\n",
    "print(f\"‚Ä¢ MAE      : {final_mae:,.0f} DH\")\n",
    "print(f\"‚Ä¢ MAPE     : {final_mape:.2f}%\")\n",
    "\n",
    "# Interpr√©tation des r√©sultats\n",
    "print(f\"\\nüí° INTERPR√âTATION:\")\n",
    "if final_r2 > 0.8:\n",
    "    print(\"‚Ä¢ üü¢ Excellent: Le mod√®le explique plus de 80% de la variance des prix\")\n",
    "elif final_r2 > 0.6:\n",
    "    print(\"‚Ä¢ üü° Bon: Le mod√®le explique plus de 60% de la variance des prix\")\n",
    "elif final_r2 > 0.4:\n",
    "    print(\"‚Ä¢ üü† Moyen: Le mod√®le explique plus de 40% de la variance des prix\")\n",
    "else:\n",
    "    print(\"‚Ä¢ üî¥ Faible: Le mod√®le explique moins de 40% de la variance des prix\")\n",
    "\n",
    "print(f\"‚Ä¢ En moyenne, le mod√®le se trompe de {final_mae:,.0f} DH sur le prix\")\n",
    "print(f\"‚Ä¢ L'erreur relative moyenne est de {final_mape:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ed9c0",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde et Chargement du Mod√®le\n",
    "\n",
    "Cette section montre comment persister le mod√®le entra√Æn√© et le recharger pour une utilisation future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f04a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Sauvegarde du mod√®le\n",
    "print(\"üíæ SAUVEGARDE DU MOD√àLE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Cr√©ation du r√©pertoire models\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Sauvegarde du meilleur mod√®le\n",
    "model_path = '../models/best_price_predictor.pkl'\n",
    "predictor.save_model(model_path)\n",
    "\n",
    "print(f\"‚úÖ Mod√®le sauvegard√©: {model_path}\")\n",
    "print(f\"üìä Mod√®le: {best_model_name}\")\n",
    "print(f\"üéØ Performance (R¬≤): {final_r2:.4f}\")\n",
    "\n",
    "# 8.2 Test du chargement du mod√®le\n",
    "print(f\"\\nüì• TEST DU CHARGEMENT DU MOD√àLE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Cr√©ation d'un nouveau pr√©dicteur pour tester le chargement\n",
    "new_predictor = RealEstatePricePredictor()\n",
    "new_predictor.load_model(model_path)\n",
    "\n",
    "print(f\"‚úÖ Mod√®le recharg√©: {new_predictor.best_model_name}\")\n",
    "\n",
    "# Test de pr√©diction avec le mod√®le recharg√©\n",
    "test_prediction = new_predictor.best_model.predict(X_test[:1])\n",
    "print(f\"üß™ Test de pr√©diction: {test_prediction[0]:,.0f} DH\")\n",
    "\n",
    "# 8.3 Exemple de pr√©diction pratique\n",
    "print(f\"\\nüè† EXEMPLE DE PR√âDICTION PRATIQUE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Propri√©t√© d'exemple\n",
    "example_property = {\n",
    "    'surface_m2': 120,\n",
    "    'nombre_chambres': 3,\n",
    "    'localisation': 'Casablanca',\n",
    "    'type_bien': 'Appartement',\n",
    "    'annee_construction': 2018\n",
    "}\n",
    "\n",
    "print(\"Caract√©ristiques de la propri√©t√©:\")\n",
    "for key, value in example_property.items():\n",
    "    print(f\"‚Ä¢ {key}: {value}\")\n",
    "\n",
    "# Note: La pr√©diction n√©cessiterait un preprocessing complet\n",
    "print(f\"\\nüí∞ Prix estim√©: [N√©cessite preprocessing complet]\")\n",
    "print(\"   (Utilisez la fonction predict_price() du module modeling)\")\n",
    "\n",
    "print(f\"\\nüéâ ANALYSE TERMIN√âE AVEC SUCC√àS!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä R√©sum√© du projet:\")\n",
    "print(f\"‚Ä¢ Donn√©es analys√©es: {len(df_cleaned)} propri√©t√©s\")\n",
    "print(f\"‚Ä¢ Meilleur mod√®le: {best_model_name}\")\n",
    "print(f\"‚Ä¢ Performance finale (R¬≤): {final_r2:.4f}\")\n",
    "print(f\"‚Ä¢ Erreur moyenne: {final_mae:,.0f} DH\")\n",
    "print(f\"‚Ä¢ Mod√®le sauvegard√©: {model_path}\")\n",
    "\n",
    "print(f\"\\nüöÄ Prochaines √©tapes recommand√©es:\")\n",
    "print(\"‚Ä¢ Collecter plus de donn√©es r√©elles\")\n",
    "print(\"‚Ä¢ Ajouter des features g√©ographiques (distance centre-ville, etc.)\")\n",
    "print(\"‚Ä¢ Tester des mod√®les plus avanc√©s (XGBoost, Neural Networks)\")\n",
    "print(\"‚Ä¢ D√©ployer le mod√®le en production\")\n",
    "print(\"‚Ä¢ Cr√©er une interface utilisateur pour les pr√©dictions\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
